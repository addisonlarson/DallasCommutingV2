if(!require(installr)) {
install.packages("installr"); require(installr)} #load / install+load installr
updateR() # this will start the updating process of your R installation.  It will check for newer versions, and if one is available, will guide you through the decisions you'd need to make.
cats <- c("Socks","Coco")
rm(list=ls())
install.packages("gdata")
library(gdata)
hpi2016 <- read.csv("https://raw.githubusercontent.com/kho777/data-visualization/master/data/hpi2016dataonly.csv")
library(ggplot2)
theme_set(theme_minimal())
plot1 <- ggplot(hpi2016, aes(Region, Happy.Planet.Index))
plot1 + geom_boxplot(varwidth = TRUE, fill = "plum") +
labs(title = "BOXPLOT!",
subtitle = "Happy Planet Index by Region, 2016",
caption = "Source: HPI",
x = "HPI",
y = "Region")
plot1 + geom_boxplot(varwidth = TRUE, fill = "cornflowerblue") +
labs(title = "BOXPLOT!",
subtitle = "Happy Planet Index by Region, 2016",
caption = "Source: HPI",
x = "HPI",
y = "Region")
head(hpi2016)
hpi <- hpi2016$Happy.Planet.Index
pop <- hpi2016$Population
summary(hpi)
fivenum(hpi)
?gsub
install.packages("gapminder")
library(gapminder)
summary(gapminder)
str(gapminder)
gm=gapminder
head(gm)
summary(gm)
table(gm$country)
# Plot one variable
hist(gm$lifeExp)
# Plot two variables with logged version of x
plot(lifeExp ~ gdpPercap, gm, subset = year == 2007, log = "x", pch=16)
# Plot two variables with selected country
plot(lifeExp ~ year, gm, subset = country == "Cambodia", type = "p")
# Try different plot types
plot(lifeExp ~ year, gm, subset = country == "Cambodia", type = "l")
# Different symbols
plot(lifeExp ~ year, gm, subset = country == "Cambodia", type = "b", pch=18)
# More layered plots using ggplot2, with regression line
install.packages("ggplot2")
library(ggplot2)
p <- ggplot(data = gm)
p + geom_point(size=2)
p <- ggplot(data = gm,
mapping = aes(x = gdpPercap,
y = lifeExp))
# Alternative
# p <- ggplot(data=gm, aes(x=gdpPercap, y=lifeExp, color=continent))
p + geom_point()
# Add some color grouping
p <- ggplot(data = gm,
mapping = aes(x = gdpPercap,
y = lifeExp, color=continent))
p + geom_point()
# Add a regression line, dropped the color grouping
p <- ggplot(data = gm,
mapping = aes(x = gdpPercap,
y = lifeExp))
p + geom_point(pch=16) + geom_smooth(method="lm")
# Add a  line, dropped the color grouping, try other method
p <- ggplot(data = gm,
mapping = aes(x = gdpPercap,
y = lifeExp))
p + geom_point(pch=16) + geom_smooth(method="loess")
# Add a regression line with logged x, dropped the color grouping
p <- ggplot(data = gm,
mapping = aes(x = gdpPercap,
y = lifeExp))
p + geom_point(pch=16) + geom_smooth(method="lm") +
scale_x_log10()
# More layered plots with ggplot2, line with other methods (Generalized Additive Model)
if (require("ggplot2")) {
p <- ggplot(data = gm)
}
p <- ggplot(data = gm,
mapping = aes(x = gdpPercap,
y = lifeExp))
p + geom_point(pch=16) + geom_smooth(method="gam") +
scale_x_log10()
# Why it is not purple?
p <- ggplot(data = gm,
mapping = aes(x = gdpPercap,
y = lifeExp,
color = "purple"))
p + geom_point() +
geom_smooth(method = "loess") +
scale_x_log10()
#  How about now?
p <- ggplot(data = gm,
mapping = aes(x = gdpPercap,
y = lifeExp))
p + geom_point(color = "purple") +
geom_smooth(method = "loess") + scale_x_log10()
p <- ggplot(data = gm)
p + geom_point(size=2)
p <- ggplot(data = gm,
mapping = aes(x = gdpPercap,
y = lifeExp))
p + geom_point()
# Add some color grouping
p <- ggplot(data = gm,
mapping = aes(x = gdpPercap,
y = lifeExp, color=continent))
p + geom_point()
pack <- function(pkg){
newpkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(newpkg))
install.packages(newpkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("foreign", "lme4")
pack(packages)
filenames <- list.files(path="E:/2018Spring/DataRegression",
pattern=".*csv")
filelist <- lapply(filenames, read.csv)
# Names for data frames
names(filelist) <- c("All",
"Pittsburgh",
"Baltimore",
"San Antonio",
"Chicago",
"Dallas",
"Denver",
"District of Columbia",
"Atlanta",
"Houston",
"Minneapolis",
"Tampa",
"Seattle",
"Los Angeles",
"Phoenix",
"Charlotte",
"Miami",
"Portland",
"Orlando",
"Philadelphia",
"Sacramento",
"San Diego",
"San Francisco",
"St. Louis",
"Boston",
"Detroit")
# Invisible function keeps lapply from spitting out the data.frames to the console
invisible(lapply(names(filelist), function(x) assign(x,filelist[[x]],envir=.GlobalEnv)))
filenames <- list.files(path="E:/2018Spring/DataRegression",
pattern=".*csv")
filelist <- lapply(filenames, read.csv)
pack <- function(pkg){
newpkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(newpkg))
install.packages(newpkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("leaflet", "rgdal", "shiny", "Rcpp", "httpuv")
pack(packages)
runExample("01_hello")
runApp('E:/Project Ideas/dccommdist')
runApp('E:/Project Ideas/dccommdist')
rm(list=ls())
pack <- function(pkg){
newpkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(newpkg))
install.packages(newpkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("foreign", "tidycensus", "tidyverse", "rgdal", "stringr")
pack(packages)
setwd("D:/AP LARSON/DallasCommutingV2")
xwalk <- read.csv("cbsatocountycrosswalk.csv")
statexwalk <- read.csv("ssa_fips_state_county2017.csv")
qualifyingMSAs <- read.csv("qualifyingMSAs.csv")
mynames <- unique(qualifyingMSAs$x)
mynames <- as.character(mynames)
countyList <- subset(xwalk, msaname %in% mynames)
countyList$newfips <- as.numeric(as.character(countyList$fipscounty))
# Need either state code or state fips separate
# in order to talk to tidycensus
statexwalk <- statexwalk[c(4,8)]
countyList <- merge(countyList, statexwalk, by = "fipscounty")
countyList$cty <- str_sub(countyList$fipscounty, -3, -1)
countyList$cty <- as.numeric(as.character(countyList$cty))
countyList <- countyList[c("msaname", "fipsstate", "cty")]
colnames(countyList) <- c("city", "st", "cty")
# This helps you get rid of factors that were once in the data frame
countyList$city <- as.factor(as.character(countyList$city))
# Instead of running separate queries for each MSA, run in a clump and split later
# listOfCities <- split(countyList, countyList$city)
setwd("D:/AP LARSON/DallasCommutingV2/censusData")
# https://stackoverflow.com/questions/45109241/r-tidycensus-download-all-block-groups
# "tidycensus can't yet handle multi-state and multi-county calls simultaneously"
# https://api.census.gov/data/2016/acs/acs5/variables.html
collect <- get_acs(geography = "tract",
state = unique(countyList$st),
geometry = FALSE,
output = "wide",
variables = c(popData = "B01001_001E",
incomeData = "B06011_001E",
povUniverse = "B08122_001E",
pov100 = "B08122_002E",
pov149 = "B08122_003E",
pov150 = "B08122_004E",
racUniverse = "B02001_001E",
racWhite = "B02001_002E",
racBlack = "B02001_003E",
racAsian = "B02001_005E",
hispUniverse = "B03001_001E",
hisp = "B03001_003E",
medRent = "B25064_001E",
# someday incl. hh size here,
medValue = "B25077_001E",
medAge = "B25035_001E",
tenureUniverse = "B25003_001E",
tenureOwn = "B25003_002E",
comUniverse = "B08012_001E",
com4 = "B08012_002E",
com5 = "B08012_003E",
com10 = "B08012_004E",
com15 = "B08012_005E",
com20 = "B08012_006E",
com25 = "B08012_007E",
com30 = "B08012_008E",
com35 = "B08012_009E",
com40 = "B08012_010E",
com45 = "B08012_011E",
com60 = "B08012_012E",
com90 = "B08012_013E"))
# Clean up fields
collect <- collect[, -( grep("\\M$" , colnames(collect), perl = TRUE))]
# Get state/county info so we can split df by MSA
collect$st <- substr(collect$GEOID, 1, 2)
collect$cty <- substr(collect$GEOID, 3, 5)
collect$st <- as.numeric(collect$st); collect$cty <- as.numeric(collect$cty)
fullCensus <- merge(collect, countyList, by = c("st", "cty"))
# Some calculations can be done in full data frame
fullCensus$logInc <- log(fullCensus$incomeData)
fullCensus$thouInc <- fullCensus$incomeData / 1000
fullCensus$pct100 <- fullCensus$pov100 / fullCensus$povUniverse * 100
fullCensus$pct149 <- fullCensus$pov100 / fullCensus$povUniverse * 100
fullCensus$pct150 <- fullCensus$pov100 / fullCensus$povUniverse * 100
fullCensus$pctWht <- fullCensus$racWhite / fullCensus$racUniverse * 100
fullCensus$pctBlk <- fullCensus$racBlack / fullCensus$racUniverse * 100
fullCensus$pctAsn <- fullCensus$racAsian / fullCensus$racUniverse * 100
fullCensus$pctHisp <- fullCensus$hisp / fullCensus$hispUniverse * 100
fullCensus$pluWht <- NA
fullCensus$pluWht <- ifelse(fullCensus$pctWht > fullCensus$pctBlk &
fullCensus$pctWht > fullCensus$pctAsn &
fullCensus$pctWht > fullCensus$pctHisp,
1, 0)
fullCensus$pluBlk <- ifelse(fullCensus$pctBlk > fullCensus$pctWht &
fullCensus$pctBlk > fullCensus$pctAsn &
fullCensus$pctBlk > fullCensus$pctHisp,
1, 0)
fullCensus$pluAsn <- ifelse(fullCensus$pctAsn > fullCensus$pctBlk &
fullCensus$pctAsn > fullCensus$pctWht &
fullCensus$pctAsn > fullCensus$pctHisp,
1, 0)
fullCensus$pluHisp <- ifelse(fullCensus$pctHisp > fullCensus$pctBlk &
fullCensus$pctHisp > fullCensus$pctAsn &
fullCensus$pctHisp > fullCensus$pctWht,
1, 0)
fullCensus$logMedRent <- log(fullCensus$medRent)
fullCensus$hunMedRent <- fullCensus$medRent / 100
fullCensus$logHousVal <- log(fullCensus$medValue)
fullCensus$thouHousVal <- fullCensus$medValue / 1000
fullCensus$medAge <- 2018 - fullCensus$medAge
fullCensus$pctOwn <- fullCensus$tenureOwn / fullCensus$tenureUniverse * 100
fullCensus$comBl10 <- (fullCensus$com4 + fullCensus$com5) / fullCensus$comUniverse * 100
fullCensus$com10 <- (fullCensus$com10 + fullCensus$com15) / fullCensus$comUniverse * 100
fullCensus$com20 <- (fullCensus$com20 + fullCensus$com25) / fullCensus$comUniverse * 100
fullCensus$com30 <- (fullCensus$com30 + fullCensus$com35) / fullCensus$comUniverse * 100
fullCensus$com40 <- (fullCensus$com40 + fullCensus$com45) / fullCensus$comUniverse * 100
fullCensus$com60 <- (fullCensus$com60 + fullCensus$com90) / fullCensus$comUniverse * 100
# Remove unnecessary columns
excludeVars <- names(fullCensus) %in% c("povUniverse",
"racUniverse",
"racWhite",
"racBlack",
"racAsian",
"hispUniverse",
"hisp",
"comUniverse",
"com4",
"com5",
"com15",
"com25",
"com35",
"com45",
"com90",
"NAME1",
"GEOID1")
fullCensus <- fullCensus[!excludeVars]
# Remove rows where population is 0
fullCensus <- fullCensus[apply(fullCensus[c(5)], 1, function(i) ! any(i == 0)),]
listOfCities <- split(fullCensus, fullCensus$city)
for (i in 1:length(listOfCities)){
myItem <- listOfCities[[i]]
myCity <- myItem$city[[i]]
write.csv(listOfCities[[i]], file = paste0("d",myCity,".csv"), row.names = FALSE)
}
View(xwalk)
rm(list=ls())
library(rgdal)
# 1. Read in all the files you need
setwd("D:/AP LARSON/DallasCommutingV2/tractShps")
MSAshps <- as.data.frame(list.files(pattern = "\\.shp$")) # list all shapefiles
colnames(MSAshps) <- "id"; MSAshps$id <- as.character(MSAshps$id)
MSAshps <- MSAshps[grepl("res", MSAshps$id),] # keep only the MSA ones
# Got some to remove. yes it's ugly
drops <- c("res_BOS_MA1.shp", "res_BOS_MA2.shp", "res_CHA_NC1.shp",
"res_CHA_NC2.shp", "res_CIN_OH1.shp", "res_CIN_OH2.shp",
"res_CIN_OH3.shp", "res_KAN_MO1.shp", "res_KAN_MO2.shp",
"res_LOU_KY1.shp", "res_LOU_KY2.shp", "res_MIN_MN1.shp",
"res_MIN_MN2.shp", "res_NOR_VA1.shp", "res_NOR_VA2.shp",
"res_POR_OR1.shp", "res_POR_OR2.shp", "res_STL_MO1.shp",
"res_STL_MO2.shp")
MSAshps <- as.data.frame(MSAshps); colnames(MSAshps) <- "id"
MSAshps <- subset(MSAshps, !(id %in% drops))
# Must remove .shp extension from end
MSAshps <- sub("\\.shp$", "", MSAshps$id)
for (i in 1:length(MSAshps)) {
assign(MSAshps[i], readOGR(".", MSAshps[i]))
}
setwd("D:/AP LARSON/DallasCommutingV2/censusData")
MSAcsvs <- list.files(pattern = "\\.csv$")
for (i in 1:length(MSAcsvs)){
assign(MSAcsvs[i], read.csv(MSAcsvs[i]))
}
setwd("D:/AP LARSON/DallasCommutingV2/tractShpsCensus")
# 1. ATLANTA, GA
currentShp <- merge(res_ATL_GA, `dATLANTA, GA.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_ATL_GA", driver = "ESRI Shapefile")
str(currentShp@data)
# 2. BALTIMORE, MD
currentShp <- merge(res_BAL_MD, `dBALTIMORE, MD.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_BAL_MD", driver = "ESRI Shapefile")
# 3. BIRMINGHAM, AL
currentShp <- merge(res_BIR_AL, `dBIRMINGHAM, AL.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
View(currentShp)
writeOGR(currentShp, ".", "mer_BIR_AL", driver = "ESRI Shapefile")
# 4. BOSTON, MA
currentShp <- merge(res_BOS_MA, `dBOSTON-WORCESTER-LAWRENCE-LOWELL-BROCKTON, MA.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_BOS_MA", driver = "ESRI Shapefile")
# 5. BUFFALO, NY
currentShp <- merge(res_BUF_NY, `dBUFFALO-NIAGARA FALLS, NY.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_BUF_NY", driver = "ESRI Shapefile")
# 6. CHARLOTTE, NC
currentShp <- merge(res_CHA_NC, `dCHARLOTTE-GASTONIA-ROCK HILL, NC-SC.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_CHA_NC", driver = "ESRI Shapefile")
# 7. CINCINNATI, OH
currentShp <- merge(res_CIN_OH, `dCINCINNATI, OH-KY-IN.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_CIN_OH", driver = "ESRI Shapefile")
# 8. CLEVELAND, OH
currentShp <- merge(res_CLE_OH, `dCLEVELAND-LORAIN-ELYRIA, OH.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_CLE_OH", driver = "ESRI Shapefile")
# 9. COLUMBUS, OH
currentShp <- merge(res_COL_OH, `dCOLUMBUS, OH.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_COL_OH", driver = "ESRI Shapefile")
# 10. DENVER, CO
currentShp <- merge(res_DEN_CO, `dDENVER, CO.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_DEN_CO", driver = "ESRI Shapefile")
# 11. HAMILTON, OH
currentShp <- merge(res_HAM_OH, `dHAMILTON-MIDDLETOWN, OH.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_HAM_OH", driver = "ESRI Shapefile")
# 12. INDIANAPOLIS, IN
currentShp <- merge(res_IND_IN, `dINDIANAPOLIS, IN.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_IND_IN", driver = "ESRI Shapefile")
# 13. KANSAS CITY, MO
currentShp <- merge(res_KAN_MO, `dKANSAS CITY, MO-KS.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_KAN_MO", driver = "ESRI Shapefile")
# 14. LOUISVILLE, KY
currentShp <- merge(res_LOU_KY, `dLOUISVILLE, KY-IN.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_LOU_KY", driver = "ESRI Shapefile")
# 15. MINNEAPOLIS, MN
currentShp <- merge(res_MIN_MN, `dMINNEAPOLIS-ST. PAUL, MN-WI.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_MIN_MN", driver = "ESRI Shapefile")
# 16. NEW ORLEANS, LA
currentShp <- merge(res_NEW_LA, `dNEW ORLEANS, LA.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_NEW_LA", driver = "ESRI Shapefile")
# 17. NORFOLK, VA
currentShp <- merge(res_NOR_VA, `dNORFOLK-VIRGINIA BEACH-NEWPORT NEWS, VA-NC.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_NOR_VA", driver = "ESRI Shapefile")
# 18. PITTSBURGH, PA
currentShp <- merge(res_PIT_PA, `dPITTSBURGH, PA.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_PIT_PA", driver = "ESRI Shapefile")
# 19. PORTLAND, OR
currentShp <- merge(res_POR_OR, `dPORTLAND-VANCOUVER,OR-WA.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_POR_OR", driver = "ESRI Shapefile")
# 20. PROVIDENCE, RI
currentShp <- merge(res_PRO_RI, `dPROVIDENCE-WARWICK-PAWTUCKET, RI.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_PRO_RI", driver = "ESRI Shapefile")
# 21. RALEIGH-DURHAM, NC
currentShp <- merge(res_RAL_NC, `dRALEIGH-DURHAM-CHAPEL HILL, NC.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_RAL_NC", driver = "ESRI Shapefile")
# 22. SACRAMENTO, CA
currentShp <- merge(res_SAC_CA, `dSACRAMENTO, CA.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_SAC_CA", driver = "ESRI Shapefile")
# 23. SAN DIEGO, CA
currentShp <- merge(res_SAND_CA, `dSAN DIEGO, CA.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_SAND_CA", driver = "ESRI Shapefile")
# 24. SAN JOSE, CA
currentShp <- merge(res_SANJ_CA, `dSAN JOSE, CA.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_SANJ_CA", driver = "ESRI Shapefile")
# 25. ST. LOUIS, MO
currentShp <- merge(res_STL_MO, `dST. LOUIS, MO-IL.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_STL_MO", driver = "ESRI Shapefile")
# 26. TAMPA, FL
currentShp <- merge(res_TAM_FL, `dTAMPA-ST. PETERSBURG-CLEARWATER, FL.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_TAM_FL", driver = "ESRI Shapefile")
# 27. YOLO, CA
currentShp <- merge(res_YOL_CA, `dYOLO, CA.csv`,
by = "GEOID")
currentShp$ALAND <- as.numeric(as.character(currentShp$ALAND))
currentShp$popDens <- currentShp$popData / (currentShp$ALAND * 0.00000038610)
writeOGR(currentShp, ".", "mer_YOL_CA", driver = "ESRI Shapefile")
rm(list=ls())

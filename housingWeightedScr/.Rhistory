countyList <- subset(xwalk, msaname %in% mynames)
countyList$newfips <- as.numeric(as.character(countyList$fipscounty))
# Need either state code or state fips separate
# in order to talk to tidycensus
statexwalk <- statexwalk[c(4,8)]
countyList <- merge(countyList, statexwalk, by = "fipscounty")
countyList$cty <- str_sub(countyList$fipscounty, -3, -1)
countyList$cty <- as.numeric(as.character(countyList$cty))
countyList <- countyList[c("msaname", "fipsstate", "cty")]
colnames(countyList) <- c("city", "st", "cty")
# This helps you get rid of factors that were once in the data frame
countyList$city <- as.factor(as.character(countyList$city))
setwd("D:/AP LARSON/DallasCommutingV2/censusData")
# https://stackoverflow.com/questions/45109241/r-tidycensus-download-all-block-groups
# "tidycensus can't yet handle multi-state and multi-county calls simultaneously"
# https://api.census.gov/data/2016/acs/acs5/variables.html
collect <- get_acs(geography = "tract",
state = unique(countyList$st),
geometry = FALSE,
output = "wide",
variables = c(popData = "B01001_001E",
incomeData = "B06011_001E",
povUniverse = "B08122_001E",
pov100 = "B08122_002E",
pov149 = "B08122_003E",
pov150 = "B08122_004E",
racUniverse = "B02001_001E",
racWhite = "B02001_002E",
racBlack = "B02001_003E",
racAsian = "B02001_005E",
hispUniverse = "B03001_001E",
hisp = "B03001_003E",
medRent = "B25064_001E",
# someday incl. hh size here,
medValue = "B25077_001E",
medAge = "B25035_001E",
tenureUniverse = "B25003_001E",
tenureOwn = "B25003_002E",
comUniverse = "B08012_001E",
com4 = "B08012_002E",
com5 = "B08012_003E",
com10 = "B08012_004E",
com15 = "B08012_005E",
com20 = "B08012_006E",
com25 = "B08012_007E",
com30 = "B08012_008E",
com35 = "B08012_009E",
com40 = "B08012_010E",
com45 = "B08012_011E",
com60 = "B08012_012E",
com90 = "B08012_013E",
bedUniverse = "B25041_001E",
bed0 = "B25041_002E",
bed1 = "B25041_003E",
bed2 = "B25041_004E",
bed3 = "B25041_005E",
bed4 = "B25041_006E",
bed5 = "B25041_007E",
plumbUniverse = "B25048_001E",
completePlumb = "B25048_002E",
kitchUniverse = "B25051_001E",
completeKitch = "B25051_002E",
laborUniverse = "B23025_002E",
unemployed = "B23025_005E",
edUniverse = "B15003_001E",
edHighSchool = "B15003_017E",
edGED = "B15003_018E",
edSomeColl = "B15003_019E",
edSomeColl2 = "B15003_020E",
edBach = "B15003_022E",
edMast = "B15003_023E",
edProf = "B15003_024E",
edDoc = "B15003_025E",
carUniverse = "B08201_001E",
zeroCar = "B08201_002E",
grapi = "B25071_001E",
famUniverse = "B11001_001E",
malHH = "B11001_005E",
femHH = "B11001_006E"))
# Clean up fields
collect <- collect[, -( grep("\\M$" , colnames(collect), perl = TRUE))]
# Get state/county info so we can split df by MSA
collect$st <- substr(collect$GEOID, 1, 2)
collect$cty <- substr(collect$GEOID, 3, 5)
collect$st <- as.numeric(collect$st); collect$cty <- as.numeric(collect$cty)
fullCensus <- merge(collect, countyList, by = c("st", "cty"))
# Some calculations can be done in full data frame
fullCensus$logInc <- log(fullCensus$incomeData)
fullCensus$thouInc <- fullCensus$incomeData / 1000
fullCensus$pct100 <- fullCensus$pov100 / fullCensus$povUniverse * 100
fullCensus$pct149 <- fullCensus$pov149 / fullCensus$povUniverse * 100
fullCensus$pct150 <- fullCensus$pov150 / fullCensus$povUniverse * 100
fullCensus$pctWht <- fullCensus$racWhite / fullCensus$racUniverse * 100
fullCensus$pctBlk <- fullCensus$racBlack / fullCensus$racUniverse * 100
fullCensus$pctAsn <- fullCensus$racAsian / fullCensus$racUniverse * 100
fullCensus$pluWht <- NA
fullCensus$pluWht <- ifelse(fullCensus$pctWht > fullCensus$pctBlk &
fullCensus$pctWht > fullCensus$pctAsn &
fullCensus$pctWht > fullCensus$pctHisp,
1, 0)
fullCensus$pctHisp <- fullCensus$hisp / fullCensus$hispUniverse * 100
fullCensus$pluBlk <- ifelse(fullCensus$pctBlk > fullCensus$pctWht &
fullCensus$pctBlk > fullCensus$pctAsn &
fullCensus$pctBlk > fullCensus$pctHisp,
1, 0)
fullCensus$pluAsn <- ifelse(fullCensus$pctAsn > fullCensus$pctBlk &
fullCensus$pctAsn > fullCensus$pctWht &
fullCensus$pctAsn > fullCensus$pctHisp,
1, 0)
fullCensus$pluHisp <- ifelse(fullCensus$pctHisp > fullCensus$pctBlk &
fullCensus$pctHisp > fullCensus$pctAsn &
fullCensus$pctHisp > fullCensus$pctWht,
1, 0)
fullCensus$logMedRent <- log(fullCensus$medRent)
fullCensus$hunMedRent <- fullCensus$medRent / 100
fullCensus$logHousVal <- log(fullCensus$medValue)
fullCensus$thouHousVal <- fullCensus$medValue / 1000
fullCensus$medAge <- 2018 - fullCensus$medAge
fullCensus$pctOwn <- fullCensus$tenureOwn / fullCensus$tenureUniverse * 100
fullCensus$comBl10 <- (fullCensus$com4 + fullCensus$com5) / fullCensus$comUniverse * 100
fullCensus$com10 <- (fullCensus$com10 + fullCensus$com15) / fullCensus$comUniverse * 100
fullCensus$com20 <- (fullCensus$com20 + fullCensus$com25) / fullCensus$comUniverse * 100
fullCensus$com30 <- (fullCensus$com30 + fullCensus$com35) / fullCensus$comUniverse * 100
fullCensus$com40 <- (fullCensus$com40 + fullCensus$com45) / fullCensus$comUniverse * 100
fullCensus$com60 <- (fullCensus$com60 + fullCensus$com90) / fullCensus$comUniverse * 100
fullCensus$bed0 <- fullCensus$bed0 / fullCensus$bedUniverse * 100
fullCensus$bed1 <- fullCensus$bed1 / fullCensus$bedUniverse * 100
fullCensus$bed2 <- fullCensus$bed2 / fullCensus$bedUniverse * 100
fullCensus$bed3 <- fullCensus$bed3 / fullCensus$bedUniverse * 100
fullCensus$bed4 <- fullCensus$bed4 / fullCensus$bedUniverse * 100
fullCensus$bed5 <- fullCensus$bed5 / fullCensus$bedUniverse * 100
fullCensus$completePlumb <- fullCensus$completePlumb / fullCensus$plumbUniverse * 100
fullCensus$completeKitch <- fullCensus$completeKitch / fullCensus$plumbUniverse * 100
fullCensus$pctUnemp <- fullCensus$unemployed / fullCensus$laborUniverse * 100
fullCensus$edHighSchool <- (fullCensus$edHighSchool + fullCensus$edGED) / fullCensus$edUniverse * 100
fullCensus$edSomeColl <- (fullCensus$edSomeColl + fullCensus$edSomeColl2) / fullCensus$edUniverse * 100
fullCensus$edBach <- fullCensus$edBach / fullCensus$edUniverse * 100
fullCensus$edGrad <- (fullCensus$edMast + fullCensus$edProf + fullCensus$edDoc) / fullCensus$edUniverse * 100
fullCensus$zeroCar <- fullCensus$zeroCar / fullCensus$carUniverse * 100
fullCensus$singParentHH <- (fullCensus$malHH + fullCensus$femHH) / fullCensus$famUniverse * 100
fullCensus <- fullCensus[which(fullCensus$popData >= 300), ] # DROP LOW POPULATION TRACTS
# Remove unnecessary columns
excludeVars <- names(fullCensus) %in% c("povUniverse",
"racUniverse",
"racWhite",
"racBlack",
"racAsian",
"hispUniverse",
"hisp",
"comUniverse",
"com4",
"com5",
"com15",
"com25",
"com35",
"com45",
"com90",
"NAME1",
"GEOID1",
"bedUniverse",
"plumbUniverse",
"kitchUniverse",
"laborUniverse",
"unemployed",
"edUniverse",
"edSomeColl2",
"edGED",
"edMast",
"edProf",
"edDoc",
"carUniverse",
"famUniverse",
"malHH",
"femHH")
fullCensus <- fullCensus[!excludeVars]
# Remove rows where population is 0
fullCensus <- fullCensus[apply(fullCensus[c(5)], 1, function(i) ! any(i == 0)),]
listOfCities <- split(fullCensus, fullCensus$city)
for (i in 1:length(listOfCities)){
myItem <- listOfCities[[i]]
myCity <- myItem$city[[i]]
write.csv(listOfCities[[i]], file = paste0("d",myCity,".csv"), row.names = FALSE)
}
# Goal here: combine information on commuting distance, HOLC, and demographic info
rm(list=ls())
pack <- function(pkg){
newpkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(newpkg))
install.packages(newpkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("foreign", "tidycensus", "tidyverse", "rgdal")
pack(packages)
setwd("D:/AP LARSON/DallasCommutingV2")
dem <- read.csv("fullDemographic.csv")
qualifiers <- read.csv("qualifyingTracts.csv")
holcIntersect <- readOGR(dsn = ".", layer = "HOLC_Dallas_overlay")
holcDf <- as.data.frame(holcIntersect)
length(unique(holcDf$GEOID)) # only 122 unique ids. Means that you need to collapse?
holcDf$quantScore <- NA
holcDf$quantScore <- ifelse(holcDf$holc_grade == "A", 4, holcDf$quantScore)
holcDf$quantScore <- ifelse(holcDf$holc_grade == "B", 3, holcDf$quantScore)
holcDf$quantScore <- ifelse(holcDf$holc_grade == "C", 2, holcDf$quantScore)
holcDf$quantScore <- ifelse(holcDf$holc_grade == "D", 1, holcDf$quantScore)
resGEOID <- aggregate(holcDf$quantScore, by = list(holcDf$GEOID), FUN = mean)
colnames(resGEOID) <- c("GEOID", "quantScore")
holcID <- merge(holcDf, resGEOID, by = "GEOID")
holcID <- holcID[!duplicated(holcID$GEOID), ]
s000 <- read.csv("S000dirdist.csv"); s000 <- s000[c(1,3)]; colnames(s000)[2] <- "s000dist"
# NEW
# Read in all shapefiles, collapse into a single data frame, OLS
rm(list=ls())
pack <- function(pkg){
newpkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(newpkg))
install.packages(newpkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("foreign", "tidycensus", "tidyverse", "rgdal", "raster")
pack(packages)
setwd("D:/AP LARSON/DallasCommutingV2/tractShps")
MSAshps <- as.data.frame(list.files(pattern = "\\.shp$")) # list all shapefiles
colnames(MSAshps) <- "id"; MSAshps$id <- as.character(MSAshps$id)
MSAshps <- MSAshps[grepl("res", MSAshps$id),] # keep only the MSA ones
# Got some to remove. yes it's ugly
drops <- c("res_BOS_MA1.shp", "res_BOS_MA2.shp", "res_CHA_NC1.shp",
"res_CHA_NC2.shp", "res_CIN_OH1.shp", "res_CIN_OH2.shp",
"res_CIN_OH3.shp", "res_KAN_MO1.shp", "res_KAN_MO2.shp",
"res_LOU_KY1.shp", "res_LOU_KY2.shp", "res_MIN_MN1.shp",
"res_MIN_MN2.shp", "res_NOR_VA1.shp", "res_NOR_VA2.shp",
"res_POR_OR1.shp", "res_POR_OR2.shp", "res_STL_MO1.shp",
"res_STL_MO2.shp")
MSAshps <- as.data.frame(MSAshps); colnames(MSAshps) <- "id"
MSAshps <- subset(MSAshps, !(id %in% drops))
# Must remove .shp extension from end
MSAshps <- sub("\\.shp$", "", MSAshps$id)
readShps <- lapply(MSAshps, shapefile)
datalist <- list()
for (i in 1:length(readShps)) {
dat <- readShps[[i]]@data
datalist[[i]] <- dat
}
datalist <- lapply(datalist, function(x) { x["layer"] <- NULL; x })
datalist <- lapply(datalist, function(x) { x["path"] <- NULL; x })
allJobs <- do.call(rbind, datalist)
allJobs <- allJobs[c(1,8,10)]
# Read in all Census datasets
setwd("D:/AP LARSON/DallasCommutingV2/censusData")
MSAcsvs <- list.files(pattern = "*.csv")
datalist <- lapply(MSAcsvs, read.csv)
allCensus <- do.call(rbind, datalist)
# Read in all HOLC data
setwd("D:/AP LARSON/DallasCommutingV2/housingWeightedScr")
MSAcsvs <- list.files(pattern = "*.csv")
datalist <- lapply(MSAcsvs, read.csv)
allHous <- do.call(rbind, datalist)
fullMerge <- merge(allCensus, allJobs, by = "GEOID")
fullMerge <- merge(fullMerge, allHous, by = "GEOID")
housOnly <- fullMerge[!is.na(fullMerge$quantScore),] # 393 obs
# SET UP FOR PANEL WOOT!
namevector <- as.character(unique(housOnly$city))
for (i in namevector){
housOnly[,namevector] <- NA
}
View(housOnly)
housOnly <- fullMerge[!is.na(fullMerge$quantScore),] # 393 obs
# SET UP FOR PANEL WOOT!
namevector <- as.character(unique(housOnly$city))
for (i in namevector){
housOnly[,namevector] <- NA
}
for (i in 1:length(namevector)){
housOnly[i + 60] <- ifelse(housOnly$city == namevector[[i]], 1, 0)
}
View(housOnly)
# add city boolean as controls
housingValue <- lm(thouHousVal ~ quantScore +
`BIRMINGHAM, AL` +
`SAN DIEGO, CA` +
`TAMPA-ST. PETERSBURG-CLEARWATER, FL` +
`ATLANTA, GA` +
`ST. LOUIS, MO-IL` +
`INDIANAPOLIS, IN` +
`KANSAS CITY, MO-KS` +
`LOUISVILLE, KY-IN` +
`NEW ORLEANS, LA` +
`BALTIMORE, MD` +
`MINNEAPOLIS-ST. PAUL, MN-WI` +
`BUFFALO-NIAGARA FALLS, NY` +
`CHARLOTTE-GASTONIA-ROCK HILL, NC-SC` +
`COLUMBUS, OH` +
`PORTLAND-VANCOUVER,OR-WA` +
`PITTSBURGH, PA` +
`NORFOLK-VIRGINIA BEACH-NEWPORT NEWS, VA-NC` +
bed0 +
bed1 +
bed2 +
bed3 +
bed4 +
medAge +
completePlumb +
completeKitch, data = housOnly)
summary(housingValue)
tenure <- lm(pctOwn ~ quantScore +
`BIRMINGHAM, AL` +
`SAN DIEGO, CA` +
`TAMPA-ST. PETERSBURG-CLEARWATER, FL` +
`ATLANTA, GA` +
`ST. LOUIS, MO-IL` +
`INDIANAPOLIS, IN` +
`KANSAS CITY, MO-KS` +
`LOUISVILLE, KY-IN` +
`NEW ORLEANS, LA` +
`BALTIMORE, MD` +
`MINNEAPOLIS-ST. PAUL, MN-WI` +
`BUFFALO-NIAGARA FALLS, NY` +
`CHARLOTTE-GASTONIA-ROCK HILL, NC-SC` +
`COLUMBUS, OH` +
`PORTLAND-VANCOUVER,OR-WA` +
`PITTSBURGH, PA` +
`NORFOLK-VIRGINIA BEACH-NEWPORT NEWS, VA-NC`, data = housOnly)
summary(tenure)
housOnly$thouJobs <- housOnly$jobs / 1000
jobAccess <- lm(thouJobs ~ quantScore +
`BIRMINGHAM, AL` +
`SAN DIEGO, CA` +
`TAMPA-ST. PETERSBURG-CLEARWATER, FL` +
`ATLANTA, GA` +
`ST. LOUIS, MO-IL` +
`INDIANAPOLIS, IN` +
`KANSAS CITY, MO-KS` +
`LOUISVILLE, KY-IN` +
`NEW ORLEANS, LA` +
`BALTIMORE, MD` +
`MINNEAPOLIS-ST. PAUL, MN-WI` +
`BUFFALO-NIAGARA FALLS, NY` +
`CHARLOTTE-GASTONIA-ROCK HILL, NC-SC` +
`COLUMBUS, OH` +
`PORTLAND-VANCOUVER,OR-WA` +
`PITTSBURGH, PA` +
`NORFOLK-VIRGINIA BEACH-NEWPORT NEWS, VA-NC`, data = housOnly)
summary(jobAccess)
income <- lm(thouInc ~ quantScore +
`BIRMINGHAM, AL` +
`SAN DIEGO, CA` +
`TAMPA-ST. PETERSBURG-CLEARWATER, FL` +
`ATLANTA, GA` +
`ST. LOUIS, MO-IL` +
`INDIANAPOLIS, IN` +
`KANSAS CITY, MO-KS` +
`LOUISVILLE, KY-IN` +
`NEW ORLEANS, LA` +
`BALTIMORE, MD` +
`MINNEAPOLIS-ST. PAUL, MN-WI` +
`BUFFALO-NIAGARA FALLS, NY` +
`CHARLOTTE-GASTONIA-ROCK HILL, NC-SC` +
`COLUMBUS, OH` +
`PORTLAND-VANCOUVER,OR-WA` +
`PITTSBURGH, PA` +
`NORFOLK-VIRGINIA BEACH-NEWPORT NEWS, VA-NC` +
edHighSchool +
edBach +
edGrad, data = housOnly)
summary(income)
comBl10 <- lm(comBl10 ~ quantScore +
`BIRMINGHAM, AL` +
`SAN DIEGO, CA` +
`TAMPA-ST. PETERSBURG-CLEARWATER, FL` +
`ATLANTA, GA` +
`ST. LOUIS, MO-IL` +
`INDIANAPOLIS, IN` +
`KANSAS CITY, MO-KS` +
`LOUISVILLE, KY-IN` +
`NEW ORLEANS, LA` +
`BALTIMORE, MD` +
`MINNEAPOLIS-ST. PAUL, MN-WI` +
`BUFFALO-NIAGARA FALLS, NY` +
`CHARLOTTE-GASTONIA-ROCK HILL, NC-SC` +
`COLUMBUS, OH` +
`PORTLAND-VANCOUVER,OR-WA` +
`PITTSBURGH, PA` +
`NORFOLK-VIRGINIA BEACH-NEWPORT NEWS, VA-NC`, data = housOnly)
summary(comBl10)
singParent <- lm(singParentHH ~ quantScore +
`BIRMINGHAM, AL` +
`SAN DIEGO, CA` +
`TAMPA-ST. PETERSBURG-CLEARWATER, FL` +
`ATLANTA, GA` +
`ST. LOUIS, MO-IL` +
`INDIANAPOLIS, IN` +
`KANSAS CITY, MO-KS` +
`LOUISVILLE, KY-IN` +
`NEW ORLEANS, LA` +
`BALTIMORE, MD` +
`MINNEAPOLIS-ST. PAUL, MN-WI` +
`BUFFALO-NIAGARA FALLS, NY` +
`CHARLOTTE-GASTONIA-ROCK HILL, NC-SC` +
`COLUMBUS, OH` +
`PORTLAND-VANCOUVER,OR-WA` +
`PITTSBURGH, PA` +
`NORFOLK-VIRGINIA BEACH-NEWPORT NEWS, VA-NC`, data = housOnly)
summary(singParent)
# Demographic Profile
rm(list=ls())
pack <- function(pkg){
newpkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(newpkg))
install.packages(newpkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("foreign", "tidycensus", "tidyverse", "rgdal", "raster")
pack(packages)
setwd("D:/AP LARSON/DallasCommutingV2/tractShps")
MSAshps <- as.data.frame(list.files(pattern = "\\.shp$")) # list all shapefiles
colnames(MSAshps) <- "id"; MSAshps$id <- as.character(MSAshps$id)
MSAshps <- MSAshps[grepl("res", MSAshps$id),] # keep only the MSA ones
# Got some to remove. yes it's ugly
drops <- c("res_BOS_MA1.shp", "res_BOS_MA2.shp", "res_CHA_NC1.shp",
"res_CHA_NC2.shp", "res_CIN_OH1.shp", "res_CIN_OH2.shp",
"res_CIN_OH3.shp", "res_KAN_MO1.shp", "res_KAN_MO2.shp",
"res_LOU_KY1.shp", "res_LOU_KY2.shp", "res_MIN_MN1.shp",
"res_MIN_MN2.shp", "res_NOR_VA1.shp", "res_NOR_VA2.shp",
"res_POR_OR1.shp", "res_POR_OR2.shp", "res_STL_MO1.shp",
"res_STL_MO2.shp")
MSAshps <- as.data.frame(MSAshps); colnames(MSAshps) <- "id"
MSAshps <- subset(MSAshps, !(id %in% drops))
# Must remove .shp extension from end
MSAshps <- sub("\\.shp$", "", MSAshps$id)
readShps <- lapply(MSAshps, shapefile)
datalist <- list()
for (i in 1:length(readShps)) {
dat <- readShps[[i]]@data
datalist[[i]] <- dat
}
datalist <- lapply(datalist, function(x) { x["layer"] <- NULL; x })
datalist <- lapply(datalist, function(x) { x["path"] <- NULL; x })
allJobs <- do.call(rbind, datalist)
allJobs <- allJobs[c(1,8,10)]
# Read in all Census datasets
setwd("D:/AP LARSON/DallasCommutingV2/censusData")
MSAcsvs <- list.files(pattern = "*.csv")
datalist <- lapply(MSAcsvs, read.csv)
allCensus <- do.call(rbind, datalist)
# Read in all HOLC data
setwd("D:/AP LARSON/DallasCommutingV2/housingWeightedScr")
MSAcsvs <- list.files(pattern = "*.csv")
datalist <- lapply(MSAcsvs, read.csv)
allHous <- do.call(rbind, datalist)
fullMerge <- merge(allCensus, allJobs, by = "GEOID")
fullMerge <- merge(fullMerge, allHous, by = "GEOID")
housOnly <- fullMerge[!is.na(fullMerge$quantScore),] # 393 obs
housOnly$grade <- NA
housOnly$grade <- cut(housOnly$quantScore,
breaks = c(0, 1.5, 2.5, 3.5, 4.5),
labels = c("D", "C", "B", "A"))
byGrade <- split(housOnly, housOnly$grade)
for (i in 1:4){
testDf <- byGrade[[i]]
print(paste("Class", i, sep = " "))
print(mean(testDf$popData, na.rm=TRUE))
print(mean(testDf$thouInc, na.rm=TRUE))
print(mean(testDf$pct100, na.rm=TRUE))
print(mean(testDf$pct149, na.rm=TRUE))
print(mean(testDf$hunMedRent, na.rm=TRUE))
print(mean(testDf$thouHousVal, na.rm=TRUE))
print(mean(testDf$medAge, na.rm=TRUE))
print(mean(testDf$edHighSchool, na.rm=TRUE))
print(mean(testDf$edBach, na.rm=TRUE))
print(mean(testDf$edGrad, na.rm=TRUE))
print(mean(testDf$pctWht, na.rm=TRUE))
print(mean(testDf$pctBlk, na.rm=TRUE))
print(mean(testDf$pctAsn, na.rm=TRUE))
print(mean(testDf$pctHisp, na.rm=TRUE))
print(mean(testDf$pluWht, na.rm=TRUE))
print(mean(testDf$pluBlk, na.rm=TRUE))
print(mean(testDf$pluAsn, na.rm=TRUE))
print(mean(testDf$pluHisp, na.rm=TRUE))
print(mean(testDf$pctUnemp, na.rm=TRUE))
print(mean(testDf$pctOwn, na.rm=TRUE))
print(mean(testDf$jobs, na.rm=TRUE))
print(mean(testDf$zeroCar, na.rm=TRUE))
print(mean(testDf$grapi, na.rm=TRUE))
}
for (i in 1:4){
testDf <- byGrade[[i]]
print(paste("Class", i, sep = " "))
# print(mean(testDf$popData, na.rm=TRUE))
# print(mean(testDf$thouInc, na.rm=TRUE))
# print(mean(testDf$pct100, na.rm=TRUE))
# print(mean(testDf$pct149, na.rm=TRUE))
print(mean(testDf$singParentHH, na.rm=TRUE))
# print(mean(testDf$hunMedRent, na.rm=TRUE))
# print(mean(testDf$thouHousVal, na.rm=TRUE))
# print(mean(testDf$medAge, na.rm=TRUE))
# print(mean(testDf$edHighSchool, na.rm=TRUE))
print(mean(testDf$edSomeColl, na.rm=TRUE))
# print(mean(testDf$edBach, na.rm=TRUE))
# print(mean(testDf$edGrad, na.rm=TRUE))
# print(mean(testDf$pctWht, na.rm=TRUE))
# print(mean(testDf$pctBlk, na.rm=TRUE))
# print(mean(testDf$pctAsn, na.rm=TRUE))
# print(mean(testDf$pctHisp, na.rm=TRUE))
# print(mean(testDf$pluWht, na.rm=TRUE))
# print(mean(testDf$pluBlk, na.rm=TRUE))
# print(mean(testDf$pluAsn, na.rm=TRUE))
# print(mean(testDf$pluHisp, na.rm=TRUE))
# print(mean(testDf$pctUnemp, na.rm=TRUE))
# print(mean(testDf$pctOwn, na.rm=TRUE))
# print(mean(testDf$jobs, na.rm=TRUE))
# print(mean(testDf$zeroCar, na.rm=TRUE))
# print(mean(testDf$grapi, na.rm=TRUE))
}

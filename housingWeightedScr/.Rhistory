N = 24 + 24
library(foreign)
crime15 <- read.csv("C:\\Users\\alarson\\Desktop\\2015crime.csv")
sum(crime15$Sum_crcoun)
mean(crime15$Sum_crcoun)
hist(crime15$Sum_crcoun)
median(crime15$Sum_crcoun)
hist(crime15$Sum_crcoun, main = "Crime Counts, 2015", xlab = "Number of Crimes", ylab = "Number of Tracts", col = "cornflowerblue")
crime15 <- read.csv("C:\\Users\\alarson\\Desktop\\Violent Crime 2015 Data.csv")
hist(crime15$Sum_Count, main = "Crime Counts, 2015", xlab = "Number of Crimes", ylab = "Number of Tracts", col = "cornflowerblue")
mean(crime15$Sum_Count)
hist(crime15$Sum_Count, main = "Violent Crime Counts, 2015", xlab = "Number of Crimes", ylab = "Number of Tracts", col = "cornflowerblue")
library(foreign)
importdata <- read.csv("C:\\Users\\alarson\\Downloads\\crazydata.csv")
importdata$JOBS <- 1000 # just for testing purposes
O = lapply(importdata, function(x) {
TEST <- as.data.frame(x)
TEST$E <- importdata$JOBS
TEST$DIV <- TEST$E / x
summs <- sum(TEST$DIV)
return(summs)})
O = lapply(importdata, function(x) {
TEST <- as.data.frame(x)
TEST$E <- importdata$JOBS
TEST$DIV <- TEST$E / x
TEST$DIV <- na.omit(TEST$DIV)
summs <- sum(TEST$DIV)
return(summs)})
O = lapply(importdata, function(x) {
TEST <- as.data.frame(x)
TEST$E <- importdata$JOBS
TEST$DIV <- TEST$E / x
TEST$DIV <- na.omit(TEST$DIV)
summs <- sum(TEST$DIV)
return(summs)})
O = lapply(importdata, function(x) {
TEST <- as.data.frame(x)
TEST$E <- importdata$JOBS
TEST$DIV <- TEST$E / x
summs <- na.omit(TEST$DIV)
summs <- sum(summs)
return(summs)})
library(foreign)
importdata <- read.csv("C:\\Users\\alarson\\Downloads\\crazydata.csv")
importdata$JOBS <- 100000 # just for testing purposes
head(importdata)
importdata$JOBS <- 100000 # just for testing purposes
importdata[importdata==is.na] <- 0
importdata <- read.csv("C:\\Users\\alarson\\Downloads\\crazydata.csv")
importdata$JOBS <- 100000 # just for testing purposes
importdata[is.na(importdata)] <- 0
O = lapply(importdata, function(x) {
TEST <- as.data.frame(x)
TEST$E <- importdata$JOBS
TEST$DIV <- TEST$E / x
summs <- sum(summs)
return(summs)})
O = lapply(importdata, function(x) {
TEST <- as.data.frame(x)
TEST$E <- importdata$JOBS
TEST$DIV <- TEST$E / x
summs <- sum(TEST$DIV)
return(summs)})
someresults <- (importdata$ORIGIN0/importdata$JOBS)
someresults <- na.omit(someresults)
sum(someresults)
myfxn <- function(E,D){
sum(E/D)
}
E <- importdata$JOBS
lapply(importdata,myfxn,E = E)
resultt <- lapply(importdata,myfxn,E = E)
head(resultt)
resultt$ORIGIN175
mapply(myfxn,importdata,E)
?apply
resultt <- apply(importdata, 2, myfxn)
importdata <- read.csv("C:\\Users\\alarson\\Downloads\\crazydata.csv")
importdata[is.na(importdata)] <- 0
E <- 10000
resultt <- lapply(importdata,myfxn,E = E)
resultt <- apply(importdata, 2, myfxn)
resultt <- apply(importdata, 2, myfxn, E = E)
resultt <- apply(D = importdata, 2, myfxn, E = E)
resultt <- apply(importdata, 2, myfxn, E = E)
myfxn <- function(x,e){
sum(e/x)
}
e <- 10000
resultt <- lapply(importdata,myfxn,e = e)
resultt <- apply(importdata, 2, myfxn, e = e)
restltt <- apply(importdata, 2, sum)
apply(importdata, 2, function(x) x/1000)
myfxn2 <- function(x,e){
e/x
}
apply(importdata, 2, myfxn2, e = e)
importdata <- read.csv("C:\\Users\\alarson\\Downloads\\crazydata.csv")
importdata[is.na(importdata)] <- 1
myfxn2 <- function(x,e){
e/x
}
apply(importdata, 2, myfxn2, e = e)
myfxn2 <- function(x,e){
sum(e/x)
}
apply(importdata, 2, myfxn2, e = e)
myfxn2 <- function(x,e){
e/x
}
apply(importdata, 2, myfxn2, e = e)
resultt <- apply(importdata, 2, myfxn2, e = e)
View(resultt)
e <- 100
myfxn2 <- function(x,e){
e/x
}
resultt <- apply(importdata, 2, myfxn2, e = e)
View(resultt)
library(foreign)
importdata <- read.csv("C:\\Users\\alarson\\Desktop\\shps\\importfile.csv")
importdata[importdata==0] <- NA
e <- importdata$jobs
myfxn2 <- function(x,e){
e/x
}
result <- apply(importdata, 2, myfxn2, e = e)
max(importdata)
max(importdata$ORIGIN101)
e <- importdata$jobs
myfxn2 <- function(x,e){
sum(e/x, na.rm = TRUE)
}
result <- apply(importdata, 2, myfxn2, e = e)
setwd("C:/Users/alarson/Desktop/")
racedata <- read.csv("2015 race data.csv")
totwht <- sum(racedata$white)
tototh <- sum(racedata$minority)
racedata$pctwht <- racedata$white/totwht
racedata$pctoth <- racedata$minority/tototh
racedata$diff <- (racedata$pctwht - racedata$pctoth)
racedata$absdiff <- abs(racedata$pctwht-racedata$pctoth)
totdiff <- sum(racedata$absdiff)
totdiff/2 # cit
View(racedata)
absupperbound <- max(racedata$absdiff)
racedata$absrescale <- racedata$absdiff / absupperbound
racedata$absrescale <- a / racedata$absrescale
racedata$absrescale <- 1 / racedata$absrescale
absupperbound <- min(racedata$absdiff)
racedata$absrescale <- racedata$absdiff / absupperbound
absupperbound <- max(racedata$absdiff)
racedata$absrescale <- racedata$absdiff / absupperbound
write.csv(racedata, file = "2015 race data w diff index.csv")
rm(list=ls())
pack <- function(pkg){
newpkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(newpkg))
install.packages(newpkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("foreign", "tidycensus", "tidyverse", "rgdal", "raster")
pack(packages)
setwd("D:/AP LARSON/DallasCommutingV2/tractShps")
MSAshps <- as.data.frame(list.files(pattern = "\\.shp$")) # list all shapefiles
MSAshps <- MSAshps[grepl("res", MSAshps$id),] # keep only the MSA ones
colnames(MSAshps) <- "id"; MSAshps$id <- as.character(MSAshps$id)
# Got some to remove. yes it's ugly
drops <- c("res_BOS_MA1.shp", "res_BOS_MA2.shp", "res_CHA_NC1.shp",
"res_CHA_NC2.shp", "res_CIN_OH1.shp", "res_CIN_OH2.shp",
"res_CIN_OH3.shp", "res_KAN_MO1.shp", "res_KAN_MO2.shp",
"res_LOU_KY1.shp", "res_LOU_KY2.shp", "res_MIN_MN1.shp",
"res_MIN_MN2.shp", "res_NOR_VA1.shp", "res_NOR_VA2.shp",
"res_POR_OR1.shp", "res_POR_OR2.shp", "res_STL_MO1.shp",
"res_STL_MO2.shp")
MSAshps <- as.data.frame(MSAshps); colnames(MSAshps) <- "id"
MSAshps <- subset(MSAshps, !(id %in% drops))
# Must remove .shp extension from end
MSAshps <- sub("\\.shp$", "", MSAshps$id)
readShps <- lapply(MSAshps, shapefile)
datalist <- list()
for (i in 1:length(readShps)) {
dat <- readShps[[i]]@data
datalist[[i]] <- dat
}
datalist <- lapply(datalist, function(x) { x["layer"] <- NULL; x })
datalist <- lapply(datalist, function(x) { x["path"] <- NULL; x })
allJobs <- do.call(rbind, datalist)
allJobs <- allJobs[c(1,8,10)]
# Read in all Census datasets
setwd("D:/AP LARSON/DallasCommutingV2/censusData")
MSAcsvs <- list.files(pattern = "*.csv")
datalist <- lapply(MSAcsvs, read.csv)
allCensus <- do.call(rbind, datalist)
# Read in all HOLC data
setwd("D:/AP LARSON/DallasCommutingV2/housingWeightedScr")
MSAcsvs <- list.files(pattern = "*.csv")
datalist <- lapply(MSAcsvs, read.csv)
allHous <- do.call(rbind, datalist)
fullMerge <- merge(allCensus, allJobs, by = "GEOID")
fullMerge <- merge(fullMerge, allHous, by = "GEOID")
housOnly <- fullMerge[!is.na(fullMerge$quantScore),] # 393 obs
rm(list=ls())
pack <- function(pkg){
newpkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(newpkg))
install.packages(newpkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("foreign", "tidycensus", "tidyverse", "rgdal", "raster")
pack(packages)
setwd("D:/AP LARSON/DallasCommutingV2/tractShps")
MSAshps <- as.data.frame(list.files(pattern = "\\.shp$")) # list all shapefiles
colnames(MSAshps) <- "id"; MSAshps$id <- as.character(MSAshps$id)
MSAshps <- MSAshps[grepl("res", MSAshps$id),] # keep only the MSA ones
# Got some to remove. yes it's ugly
drops <- c("res_BOS_MA1.shp", "res_BOS_MA2.shp", "res_CHA_NC1.shp",
"res_CHA_NC2.shp", "res_CIN_OH1.shp", "res_CIN_OH2.shp",
"res_CIN_OH3.shp", "res_KAN_MO1.shp", "res_KAN_MO2.shp",
"res_LOU_KY1.shp", "res_LOU_KY2.shp", "res_MIN_MN1.shp",
"res_MIN_MN2.shp", "res_NOR_VA1.shp", "res_NOR_VA2.shp",
"res_POR_OR1.shp", "res_POR_OR2.shp", "res_STL_MO1.shp",
"res_STL_MO2.shp")
MSAshps <- as.data.frame(MSAshps); colnames(MSAshps) <- "id"
MSAshps <- subset(MSAshps, !(id %in% drops))
# Must remove .shp extension from end
MSAshps <- sub("\\.shp$", "", MSAshps$id)
readShps <- lapply(MSAshps, shapefile)
datalist <- list()
for (i in 1:length(readShps)) {
dat <- readShps[[i]]@data
datalist[[i]] <- dat
}
datalist <- lapply(datalist, function(x) { x["layer"] <- NULL; x })
datalist <- lapply(datalist, function(x) { x["path"] <- NULL; x })
allJobs <- do.call(rbind, datalist)
allJobs <- allJobs[c(1,8,10)]
# Read in all Census datasets
setwd("D:/AP LARSON/DallasCommutingV2/censusData")
MSAcsvs <- list.files(pattern = "*.csv")
datalist <- lapply(MSAcsvs, read.csv)
allCensus <- do.call(rbind, datalist)
# Read in all HOLC data
setwd("D:/AP LARSON/DallasCommutingV2/housingWeightedScr")
MSAcsvs <- list.files(pattern = "*.csv")
datalist <- lapply(MSAcsvs, read.csv)
allHous <- do.call(rbind, datalist)
fullMerge <- merge(allCensus, allJobs, by = "GEOID")
fullMerge <- merge(fullMerge, allHous, by = "GEOID")
housOnly <- fullMerge[!is.na(fullMerge$quantScore),] # 393 obs
# SET UP FOR PANEL WOOT!
namevector <- as.character(unique(housOnly$city))
for (i in namevector){
housOnly[,namevector] <- NA
}
for (i in 1:length(namevector)){
housOnly[i + 60] <- ifelse(housOnly$city == namevector[[i]], 1, 0)
}
View(housOnly)
housOnly <- fullMerge[!is.na(fullMerge$quantScore),] # 393 obs
# Get back the white and black raw numbers
fullMerge$blk <- fullMerge$pctBlk * fullMerge$popData
fullMerge$wht <- fullMerge$pctWht * fullMerge$popData
housOnly <- fullMerge[!is.na(fullMerge$quantScore),] # 393 obs
MSAsplit <- split(fullMerge, fullMerge$city)
housOnly <- split(housOnly, housOnly$city)
View(housOnly)
fullMerge$city <- as.character(fullMerge$city)
housOnly <- fullMerge[!is.na(fullMerge$quantScore),] # 393 obs
MSAsplit <- split(fullMerge, fullMerge$city)
housOnly <- split(housOnly, housOnly$city)
View(MSAsplit)
rm(list=ls())
pack <- function(pkg){
newpkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(newpkg))
install.packages(newpkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("foreign", "tidycensus", "tidyverse", "rgdal", "raster")
pack(packages)
setwd("D:/AP LARSON/DallasCommutingV2/tractShps")
MSAshps <- as.data.frame(list.files(pattern = "\\.shp$")) # list all shapefiles
colnames(MSAshps) <- "id"; MSAshps$id <- as.character(MSAshps$id)
MSAshps <- MSAshps[grepl("res", MSAshps$id),] # keep only the MSA ones
# Got some to remove. yes it's ugly
drops <- c("res_BOS_MA1.shp", "res_BOS_MA2.shp", "res_CHA_NC1.shp",
"res_CHA_NC2.shp", "res_CIN_OH1.shp", "res_CIN_OH2.shp",
"res_CIN_OH3.shp", "res_KAN_MO1.shp", "res_KAN_MO2.shp",
"res_LOU_KY1.shp", "res_LOU_KY2.shp", "res_MIN_MN1.shp",
"res_MIN_MN2.shp", "res_NOR_VA1.shp", "res_NOR_VA2.shp",
"res_POR_OR1.shp", "res_POR_OR2.shp", "res_STL_MO1.shp",
"res_STL_MO2.shp")
MSAshps <- as.data.frame(MSAshps); colnames(MSAshps) <- "id"
MSAshps <- subset(MSAshps, !(id %in% drops))
# Must remove .shp extension from end
MSAshps <- sub("\\.shp$", "", MSAshps$id)
readShps <- lapply(MSAshps, shapefile)
datalist <- list()
for (i in 1:length(readShps)) {
dat <- readShps[[i]]@data
datalist[[i]] <- dat
}
datalist <- lapply(datalist, function(x) { x["layer"] <- NULL; x })
datalist <- lapply(datalist, function(x) { x["path"] <- NULL; x })
allJobs <- do.call(rbind, datalist)
allJobs <- allJobs[c(1,8,10)]
# Read in all Census datasets
setwd("D:/AP LARSON/DallasCommutingV2/censusData")
MSAcsvs <- list.files(pattern = "*.csv")
datalist <- lapply(MSAcsvs, read.csv)
allCensus <- do.call(rbind, datalist)
# Read in all HOLC data
setwd("D:/AP LARSON/DallasCommutingV2/housingWeightedScr")
MSAcsvs <- list.files(pattern = "*.csv")
datalist <- lapply(MSAcsvs, read.csv)
allHous <- do.call(rbind, datalist)
fullMerge <- merge(allCensus, allJobs, by = "GEOID")
fullMerge <- merge(fullMerge, allHous, by = "GEOID")
# Get back the white and black raw numbers
fullMerge$blk <- fullMerge$pctBlk * fullMerge$popData
fullMerge$wht <- fullMerge$pctWht * fullMerge$popData
fullMerge$city <- as.character(fullMerge$city)
unique(fullMerge$city)
# Must drop San Jose and Sacramento: They don't exist in HOLC
fullMerge <- fullMerge[which(fullMerge$city != "SACRAMENTO, CA" &
fullMerge$city != "SAN JOSE, CA"), ]
housOnly <- fullMerge[!is.na(fullMerge$quantScore),] # 393 obs
MSAsplit <- split(fullMerge, fullMerge$city)
housOnly <- split(housOnly, housOnly$city)
for (i in 1:17){
mydf <- fullMerge[[i]]
totwht <- sum(mydf$wht)
totblk <- sum(mydf$blk)
mydf$newwht <- mydf$wht / totwht
mydf$newblk <- mydf$blk / totblk
mydf$absdiff <- abs(mydf$newwht - mydf$newblk)
totdiff <- sum(mydf$absdiff) / 2
print(unique(mydf$city))
print(totdiff)
}
for (i in 1:17){
mydf <- fullMerge[[i]]
# totwht <- sum(mydf$wht)
# totblk <- sum(mydf$blk)
# mydf$newwht <- mydf$wht / totwht
# mydf$newblk <- mydf$blk / totblk
# mydf$absdiff <- abs(mydf$newwht - mydf$newblk)
# totdiff <- sum(mydf$absdiff) / 2
# print(unique(mydf$city))
# print(totdiff)
}
for (i in 1:17){
mydf <- MSAsplit[[i]]
totwht <- sum(mydf$wht)
totblk <- sum(mydf$blk)
mydf$newwht <- mydf$wht / totwht
mydf$newblk <- mydf$blk / totblk
mydf$absdiff <- abs(mydf$newwht - mydf$newblk)
totdiff <- sum(mydf$absdiff) / 2
print(unique(mydf$city))
print(totdiff)
}
for (i in 1:17){
mydf <- housOnly[[i]]
totwht <- sum(mydf$wht)
totblk <- sum(mydf$blk)
mydf$newwht <- mydf$wht / totwht
mydf$newblk <- mydf$blk / totblk
mydf$absdiff <- abs(mydf$newwht - mydf$newblk)
totdiff <- sum(mydf$absdiff) / 2
print(unique(mydf$city))
print(totdiff)
}
# What's up with Portland and Norfolk in HousOnly?
housOnly$`PORTLAND-VANCOUVER,OR-WA`
View(housOnly)
